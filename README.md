# lmm_multi_token

TODO
* multi gpu
* non LORA
* efficent batch encoding/projection
* efficent batch collation
* efficent batch inference
* allow generate cache
* dont hard code INST